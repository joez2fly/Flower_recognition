{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-04T04:32:13.027655Z","iopub.execute_input":"2023-04-04T04:32:13.028054Z","iopub.status.idle":"2023-04-04T04:32:13.034181Z","shell.execute_reply.started":"2023-04-04T04:32:13.028014Z","shell.execute_reply":"2023-04-04T04:32:13.032950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q efficientnet","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:32:13.036953Z","iopub.execute_input":"2023-04-04T04:32:13.037543Z","iopub.status.idle":"2023-04-04T04:32:22.602842Z","shell.execute_reply.started":"2023-04-04T04:32:13.037502Z","shell.execute_reply":"2023-04-04T04:32:22.601355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os \nimport random\nimport math\nfrom matplotlib import pyplot as plt\nimport cv2\nfrom tqdm.notebook import tqdm\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\n#import efficientnet.tfkeras as efn\nfrom tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2L\nimport efficientnet.tfkeras as efn\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.models import Sequential\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras import layers\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import Input, Conv2D \nfrom tensorflow.keras.layers import MaxPool2D, Flatten, Dense \nfrom tensorflow.keras import Model\n\n\nfrom keras.utils.np_utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:32:22.604739Z","iopub.execute_input":"2023-04-04T04:32:22.605716Z","iopub.status.idle":"2023-04-04T04:32:22.616174Z","shell.execute_reply.started":"2023-04-04T04:32:22.605669Z","shell.execute_reply":"2023-04-04T04:32:22.615087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set Random Seed\ndef set_seed(seed: int = 42) -> None:\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    tf.experimental.numpy.random.seed(seed)\n    \n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    print(f\"Random seed set as {seed}\")\nset_seed()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:32:22.619900Z","iopub.execute_input":"2023-04-04T04:32:22.620281Z","iopub.status.idle":"2023-04-04T04:32:22.694529Z","shell.execute_reply.started":"2023-04-04T04:32:22.620254Z","shell.execute_reply":"2023-04-04T04:32:22.693463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configuration\nIMAGE_SIZE = 224\nBATCH_SIZE = 16 ","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:32:22.698833Z","iopub.execute_input":"2023-04-04T04:32:22.699213Z","iopub.status.idle":"2023-04-04T04:32:22.705921Z","shell.execute_reply.started":"2023-04-04T04:32:22.699177Z","shell.execute_reply":"2023-04-04T04:32:22.704844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.Preprocessing","metadata":{}},{"cell_type":"code","source":"raw_dir = '/kaggle/input/flower-image-dataset/flowers'\npaths = []\nlabels = []\nfor i in os.listdir(raw_dir):\n    paths.append(os.path.join(raw_dir,i))\n    labels.append(i.split('_')[0])\n\nraw_input = pd.DataFrame({'path':paths,\n                          'label':labels})\nraw_input.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:32:22.707556Z","iopub.execute_input":"2023-04-04T04:32:22.708217Z","iopub.status.idle":"2023-04-04T04:32:22.727085Z","shell.execute_reply.started":"2023-04-04T04:32:22.708180Z","shell.execute_reply":"2023-04-04T04:32:22.726185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the number of images from each category\ndf_count = raw_input['label'].value_counts().rename_axis('label').reset_index(name='counts')\ndf_count","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:32:22.728427Z","iopub.execute_input":"2023-04-04T04:32:22.728841Z","iopub.status.idle":"2023-04-04T04:32:22.742315Z","shell.execute_reply.started":"2023-04-04T04:32:22.728805Z","shell.execute_reply":"2023-04-04T04:32:22.741207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert label to Int category\nLE = LabelEncoder()\nraw_input['category'] = LE.fit_transform(raw_input['label'])","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:32:22.743763Z","iopub.execute_input":"2023-04-04T04:32:22.744437Z","iopub.status.idle":"2023-04-04T04:32:22.750399Z","shell.execute_reply.started":"2023-04-04T04:32:22.744398Z","shell.execute_reply":"2023-04-04T04:32:22.749145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check Encoding\nraw_input[['label','category']].drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:32:22.751849Z","iopub.execute_input":"2023-04-04T04:32:22.752466Z","iopub.status.idle":"2023-04-04T04:32:22.767313Z","shell.execute_reply.started":"2023-04-04T04:32:22.752432Z","shell.execute_reply":"2023-04-04T04:32:22.766135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_input.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:32:22.772497Z","iopub.execute_input":"2023-04-04T04:32:22.773332Z","iopub.status.idle":"2023-04-04T04:32:22.783088Z","shell.execute_reply.started":"2023-04-04T04:32:22.773297Z","shell.execute_reply":"2023-04-04T04:32:22.782056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.Prepare Images","metadata":{}},{"cell_type":"code","source":"# Prepare images\nall_images = []\nfor i in tqdm(paths):\n    image = cv2.imread(i)\n    image = cv2.resize(image,(IMAGE_SIZE,IMAGE_SIZE),interpolation=cv2.INTER_AREA)\n    all_images.append(image)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:32:22.784502Z","iopub.execute_input":"2023-04-04T04:32:22.785651Z","iopub.status.idle":"2023-04-04T04:32:57.212385Z","shell.execute_reply.started":"2023-04-04T04:32:22.785615Z","shell.execute_reply":"2023-04-04T04:32:57.211218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Plotting Random 9 Images for each Flower Category\nfor label in df_count.label.values:\n    print(f\"Start Plotting Random Images for \\033[1m{label}\\033[0m Flowers\")\n    image_index = sorted(random.sample(set(raw_input[raw_input['label']==label].index), 9))\n    plt.figure(figsize=(10,10))\n    for i in range(9):\n        plt.subplot(3,3,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(f'{label} - Index: {image_index[i]}') \n        plt.grid(False)\n        plt.imshow(cv2.cvtColor(all_images[image_index[i]], cv2.COLOR_BGR2RGB))\n    plt.show()\n    print(\" \")\n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:32:57.215501Z","iopub.execute_input":"2023-04-04T04:32:57.215790Z","iopub.status.idle":"2023-04-04T04:33:05.568413Z","shell.execute_reply.started":"2023-04-04T04:32:57.215762Z","shell.execute_reply":"2023-04-04T04:33:05.567361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot first 25 images with label\nplt.figure(figsize=(10,10))\nfor i in range(25) :\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(labels[i]) \n    plt.grid(False)\n    plt.imshow(cv2.cvtColor(all_images[i], cv2.COLOR_BGR2RGB))","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:05.569601Z","iopub.execute_input":"2023-04-04T04:33:05.571418Z","iopub.status.idle":"2023-04-04T04:33:06.976683Z","shell.execute_reply.started":"2023-04-04T04:33:05.571382Z","shell.execute_reply":"2023-04-04T04:33:06.975577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.Train test split","metadata":{}},{"cell_type":"code","source":"# Train test split\nX = raw_input['path'].values\ny = to_categorical(raw_input['category'], num_classes = 10)\nX_2, X_test, y_2, y_test = train_test_split(X, y, test_size=0.095, random_state=42,shuffle = True, stratify = y)\nX_train, X_val, y_train, y_val = train_test_split(X_2, y_2, test_size=0.2, random_state=42,shuffle = True, stratify = y_2)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:06.978296Z","iopub.execute_input":"2023-04-04T04:33:06.978954Z","iopub.status.idle":"2023-04-04T04:33:07.011628Z","shell.execute_reply.started":"2023-04-04T04:33:06.978915Z","shell.execute_reply":"2023-04-04T04:33:07.010325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'X_train has {len(X_train)} images; X_val has {len(X_val)} images; X_test has {len(X_test)} images')","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:07.013396Z","iopub.execute_input":"2023-04-04T04:33:07.014087Z","iopub.status.idle":"2023-04-04T04:33:07.019934Z","shell.execute_reply.started":"2023-04-04T04:33:07.014050Z","shell.execute_reply":"2023-04-04T04:33:07.018889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.Prepare Tensorflow Dataset","metadata":{}},{"cell_type":"code","source":"# Prepare Data\n\ndef load_dataset(filepath,label):\n    dataset = tf.data.Dataset.from_tensor_slices((filepath, label))\n    return dataset\n\n\ndef decode_image(filepath, label=None):\n    image = tf.io.read_file(filepath)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\ndef data_augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:07.021287Z","iopub.execute_input":"2023-04-04T04:33:07.022386Z","iopub.status.idle":"2023-04-04T04:33:07.032174Z","shell.execute_reply.started":"2023-04-04T04:33:07.022351Z","shell.execute_reply":"2023-04-04T04:33:07.030901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.1.Rotation Transformation ","metadata":{}},{"cell_type":"code","source":"# Get idea from https://www.kaggle.com/code/cdeotte/rotation-augmentation-gpu-tpu-0-96\n\ndef get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n    # returns 3x3 transformmatrix which transforms indicies\n        \n    # CONVERT DEGREES TO RADIANS\n    rotation = math.pi * rotation / 180.\n    shear = math.pi * shear / 180.\n    \n    # ROTATION MATRIX\n    c1 = tf.math.cos(rotation)\n    s1 = tf.math.sin(rotation)\n    one = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n        \n    # SHEAR MATRIX\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)\n    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    \n    \n    # ZOOM MATRIX\n    zoom_matrix = tf.reshape( tf.concat([one/height_zoom,zero,zero, zero,one/width_zoom,zero, zero,zero,one],axis=0),[3,3] )\n    \n    # SHIFT MATRIX\n    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )\n    \n    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:07.033823Z","iopub.execute_input":"2023-04-04T04:33:07.034605Z","iopub.status.idle":"2023-04-04T04:33:07.046453Z","shell.execute_reply.started":"2023-04-04T04:33:07.034570Z","shell.execute_reply":"2023-04-04T04:33:07.045353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform(image,label):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly rotated, sheared, zoomed, and shifted\n    DIM = IMAGE_SIZE\n    XDIM = DIM%2 #fix for size 331\n    \n    rot = 15. * tf.random.normal([1],dtype='float32')\n    shr = 5. * tf.random.normal([1],dtype='float32') \n    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n    h_shift = 16. * tf.random.normal([1],dtype='float32') \n    w_shift = 16. * tf.random.normal([1],dtype='float32') \n  \n    # GET TRANSFORMATION MATRIX\n    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n\n    # LIST DESTINATION PIXEL INDICES\n    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n    z = tf.ones([DIM*DIM],dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n    idx2 = K.cast(idx2,dtype='int32')\n    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n    \n    # FIND ORIGIN PIXEL VALUES           \n    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n    d = tf.gather_nd(image,tf.transpose(idx3))\n        \n    return tf.reshape(d,[DIM,DIM,3]),label","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:07.047981Z","iopub.execute_input":"2023-04-04T04:33:07.048557Z","iopub.status.idle":"2023-04-04T04:33:07.060821Z","shell.execute_reply.started":"2023-04-04T04:33:07.048518Z","shell.execute_reply":"2023-04-04T04:33:07.059823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2.Prepare Train/Test/Valid Dataset","metadata":{}},{"cell_type":"code","source":"def get_training_dataset(dataset,do_aug=True):\n    dataset = dataset.map(decode_image)\n    dataset = dataset.cache()\n    dataset = dataset.map(data_augment)\n    if do_aug: \n        dataset = dataset.map(transform)\n    #dataset = dataset.shuffle(128)\n    dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n    return dataset\n\ndef get_validation_dataset(dataset):\n    dataset = dataset.map(decode_image)\n    dataset = dataset.cache()\n    dataset = dataset.batch(BATCH_SIZE)\n    return dataset\n\ndef get_test_dataset(dataset):\n    dataset = dataset.map(decode_image)\n    dataset = dataset.cache()\n    dataset = dataset.batch(BATCH_SIZE)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:07.062878Z","iopub.execute_input":"2023-04-04T04:33:07.063286Z","iopub.status.idle":"2023-04-04T04:33:07.073475Z","shell.execute_reply.started":"2023-04-04T04:33:07.063249Z","shell.execute_reply":"2023-04-04T04:33:07.072455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display Augmentation Example\n\nrow = 4; col = 4;\nall_elements = get_training_dataset(load_dataset(X_train, y_train),do_aug=False).unbatch()\none_element = tf.data.Dataset.from_tensors( next(iter(all_elements)) )\naugmented_element = one_element.repeat().map(transform).batch(row*col)\n\nfor (img,label) in augmented_element:\n    plt.figure(figsize=(10,int(10*row/col)))\n    for j in range(row*col):\n        plt.subplot(row,col,j+1)\n        plt.axis('off')\n        plt.imshow(img[j,])\n    plt.show()\n    break","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:07.074795Z","iopub.execute_input":"2023-04-04T04:33:07.075220Z","iopub.status.idle":"2023-04-04T04:33:08.959102Z","shell.execute_reply.started":"2023-04-04T04:33:07.075185Z","shell.execute_reply":"2023-04-04T04:33:08.958220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3.Get Train/Test/Valid Dataset","metadata":{}},{"cell_type":"code","source":"# train_dataset = get_training_dataset(load_dataset(X_train, y_train),do_aug=True)\n\n# valid_dataset = get_validation_dataset(load_dataset(X_val, y_val))\n\n# test_dataset =  get_test_dataset(load_dataset(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:08.961243Z","iopub.execute_input":"2023-04-04T04:33:08.962094Z","iopub.status.idle":"2023-04-04T04:33:08.970686Z","shell.execute_reply.started":"2023-04-04T04:33:08.962042Z","shell.execute_reply":"2023-04-04T04:33:08.969367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.Build Model","metadata":{}},{"cell_type":"markdown","source":"## 5.1.VGG16 - From Scratch - 224*224","metadata":{}},{"cell_type":"code","source":"# # input\n\n# input = Input(shape =(IMAGE_SIZE,IMAGE_SIZE,3))\n# # 1st Conv Block\n\n# x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(input)\n# x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(x)\n# x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n# # 2nd Conv Block\n\n# x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)\n# x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)\n# x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n# # 3rd Conv block\n\n# x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n# x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n# x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n# x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n# # 4th Conv block\n\n# x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n# x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n# x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n# x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n\n# # 5th Conv block\n\n# x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n# x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n# x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n# x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n# # Fully connected layers\n\n# x = Flatten()(x)\n# x = Dense(units = 4096, activation ='relu')(x)\n# x = Dense(units = 4096, activation ='relu')(x)\n# output = Dense(units = 10, activation ='softmax')(x)\n# # creating the model\n\n# model = Model (inputs=input, outputs =output)\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:08.972550Z","iopub.execute_input":"2023-04-04T04:33:08.973362Z","iopub.status.idle":"2023-04-04T04:33:08.980053Z","shell.execute_reply.started":"2023-04-04T04:33:08.973326Z","shell.execute_reply":"2023-04-04T04:33:08.978595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.compile(\n#                 optimizer = 'Adam',\n#                 loss = 'categorical_crossentropy',\n#                 metrics=['categorical_accuracy']\n#               )","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:08.981530Z","iopub.execute_input":"2023-04-04T04:33:08.982626Z","iopub.status.idle":"2023-04-04T04:33:08.990801Z","shell.execute_reply.started":"2023-04-04T04:33:08.982593Z","shell.execute_reply":"2023-04-04T04:33:08.989614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5)\n# history = model.fit(train_dataset,validation_data=valid_dataset,epochs=30, callbacks = [early_stopping])","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:08.992703Z","iopub.execute_input":"2023-04-04T04:33:08.993369Z","iopub.status.idle":"2023-04-04T04:33:08.998799Z","shell.execute_reply.started":"2023-04-04T04:33:08.993333Z","shell.execute_reply":"2023-04-04T04:33:08.997643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2.VGG16 - Transfer Learning - 224*224","metadata":{}},{"cell_type":"code","source":"# base_model = tf.keras.applications.VGG16(weights = 'imagenet', include_top = False, input_shape = (IMAGE_SIZE,IMAGE_SIZE,3))\n# for layer in base_model.layers:\n#     layer.trainable = False\n# base_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:09.000642Z","iopub.execute_input":"2023-04-04T04:33:09.001318Z","iopub.status.idle":"2023-04-04T04:33:09.009507Z","shell.execute_reply.started":"2023-04-04T04:33:09.001273Z","shell.execute_reply":"2023-04-04T04:33:09.008216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = tf.keras.Sequential([\n#             base_model,\n#             tf.keras.layers.Flatten(),\n#             tf.keras.layers.Dense(4096, activation='relu'),\n#             tf.keras.layers.Dense(4096, activation='relu'),\n#             tf.keras.layers.Dense(10, activation='softmax')\n#                             ])\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:09.011181Z","iopub.execute_input":"2023-04-04T04:33:09.012500Z","iopub.status.idle":"2023-04-04T04:33:09.017495Z","shell.execute_reply.started":"2023-04-04T04:33:09.012465Z","shell.execute_reply":"2023-04-04T04:33:09.016310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.compile(\n#                 optimizer = 'Adam',\n#                 loss = 'categorical_crossentropy',\n#                 metrics=['categorical_accuracy']\n#               )","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:09.019184Z","iopub.execute_input":"2023-04-04T04:33:09.020252Z","iopub.status.idle":"2023-04-04T04:33:09.026599Z","shell.execute_reply.started":"2023-04-04T04:33:09.020135Z","shell.execute_reply":"2023-04-04T04:33:09.025513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5)\n# history = model.fit(train_dataset,validation_data=valid_dataset,epochs=30, callbacks = [early_stopping])","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:09.036019Z","iopub.execute_input":"2023-04-04T04:33:09.037376Z","iopub.status.idle":"2023-04-04T04:33:09.041532Z","shell.execute_reply.started":"2023-04-04T04:33:09.037339Z","shell.execute_reply":"2023-04-04T04:33:09.040373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Plotting Model Loss Performance\n# fig = plt.figure()\n# plt.plot(history.history['loss'], color='green', label='loss')\n# plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n# fig.suptitle('Loss', fontsize=20)\n# plt.legend(loc='upper right')\n# plt.xlabel('Epoch', fontsize=18)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:09.043111Z","iopub.execute_input":"2023-04-04T04:33:09.043586Z","iopub.status.idle":"2023-04-04T04:33:09.050263Z","shell.execute_reply.started":"2023-04-04T04:33:09.043550Z","shell.execute_reply":"2023-04-04T04:33:09.049486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Plotting Model Accuracy Performance\n# fig = plt.figure()\n# plt.plot(history.history['categorical_accuracy'], color='green', label='accuracy')\n# plt.plot(history.history['val_categorical_accuracy'], color='orange', label='val_accuracy')\n# fig.suptitle('Accuracy', fontsize=20)\n# plt.legend(loc='lower right')\n# plt.xlabel('Epoch', fontsize=18)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:09.052022Z","iopub.execute_input":"2023-04-04T04:33:09.052890Z","iopub.status.idle":"2023-04-04T04:33:09.058317Z","shell.execute_reply.started":"2023-04-04T04:33:09.052854Z","shell.execute_reply":"2023-04-04T04:33:09.057506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_acc = model.evaluate(test_dataset)[1]\n# print(f'Accuracy on Test(Unseen) Dataset is \\033[1m{test_acc:.2%}\\033[0m')","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:09.059915Z","iopub.execute_input":"2023-04-04T04:33:09.060738Z","iopub.status.idle":"2023-04-04T04:33:09.066381Z","shell.execute_reply.started":"2023-04-04T04:33:09.060701Z","shell.execute_reply":"2023-04-04T04:33:09.065619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.3.EfficientnetB7 - 224*224","metadata":{}},{"cell_type":"code","source":"# efnet = efn.EfficientNetB7(\n#     input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n#     weights='noisy-student',\n#     include_top=False,\n#     pooling='avg')\n# efnet.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:09.068003Z","iopub.execute_input":"2023-04-04T04:33:09.068848Z","iopub.status.idle":"2023-04-04T04:33:09.074536Z","shell.execute_reply.started":"2023-04-04T04:33:09.068812Z","shell.execute_reply":"2023-04-04T04:33:09.073540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  model = tf.keras.Sequential([\n#             efnet,\n#             tf.keras.layers.Dense(128, activation='relu'),\n#             tf.keras.layers.Dense(10, activation='softmax')\n#                             ])","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:09.076812Z","iopub.execute_input":"2023-04-04T04:33:09.077098Z","iopub.status.idle":"2023-04-04T04:33:09.085188Z","shell.execute_reply.started":"2023-04-04T04:33:09.077073Z","shell.execute_reply":"2023-04-04T04:33:09.084202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.compile(\n#                 optimizer = 'Adam',\n#                 loss = 'categorical_crossentropy',\n#                 metrics=['categorical_accuracy']\n#               )\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:09.086423Z","iopub.execute_input":"2023-04-04T04:33:09.086667Z","iopub.status.idle":"2023-04-04T04:33:09.094100Z","shell.execute_reply.started":"2023-04-04T04:33:09.086643Z","shell.execute_reply":"2023-04-04T04:33:09.092830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5)\n# history = model.fit(train_dataset,validation_data=valid_dataset,epochs=30, callbacks = [early_stopping])","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:09.095507Z","iopub.execute_input":"2023-04-04T04:33:09.096111Z","iopub.status.idle":"2023-04-04T04:33:09.102375Z","shell.execute_reply.started":"2023-04-04T04:33:09.096076Z","shell.execute_reply":"2023-04-04T04:33:09.100918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Plotting Model Loss Performance\n# fig = plt.figure()\n# plt.plot(history.history['loss'], color='green', label='loss')\n# plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n# fig.suptitle('Loss', fontsize=20)\n# plt.legend(loc='upper right')\n# plt.xlabel('Epoch', fontsize=18)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:09.103851Z","iopub.execute_input":"2023-04-04T04:33:09.104457Z","iopub.status.idle":"2023-04-04T04:33:09.109858Z","shell.execute_reply.started":"2023-04-04T04:33:09.104429Z","shell.execute_reply":"2023-04-04T04:33:09.108937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_acc = model.evaluate(test_dataset)[1]\n# print(f'Accuracy on Test(Unseen) Dataset is \\033[1m{test_acc:.2%}\\033[0m')","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:09.111255Z","iopub.execute_input":"2023-04-04T04:33:09.111635Z","iopub.status.idle":"2023-04-04T04:33:09.117449Z","shell.execute_reply.started":"2023-04-04T04:33:09.111602Z","shell.execute_reply":"2023-04-04T04:33:09.116549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.4.EfficientnetB7 - 800*800","metadata":{"execution":{"iopub.status.busy":"2023-03-28T17:50:56.471522Z","iopub.execute_input":"2023-03-28T17:50:56.472473Z","iopub.status.idle":"2023-03-28T17:50:56.477357Z","shell.execute_reply.started":"2023-03-28T17:50:56.472421Z","shell.execute_reply":"2023-03-28T17:50:56.476025Z"}}},{"cell_type":"code","source":"# Get new dataset\nIMAGE_SIZE = 600\n\ntrain_dataset = get_training_dataset(load_dataset(X_train, y_train),do_aug=True)\n\nvalid_dataset = get_validation_dataset(load_dataset(X_val, y_val))\n\ntest_dataset =  get_test_dataset(load_dataset(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:09.118821Z","iopub.execute_input":"2023-04-04T04:33:09.119286Z","iopub.status.idle":"2023-04-04T04:33:09.318829Z","shell.execute_reply.started":"2023-04-04T04:33:09.119100Z","shell.execute_reply":"2023-04-04T04:33:09.317743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"efnet = efn.EfficientNetB0(\n    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n    weights='noisy-student',\n    include_top=False,\n    pooling='avg')\nefnet.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:09.320645Z","iopub.execute_input":"2023-04-04T04:33:09.320966Z","iopub.status.idle":"2023-04-04T04:33:11.541639Z","shell.execute_reply.started":"2023-04-04T04:33:09.320938Z","shell.execute_reply":"2023-04-04T04:33:11.540581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" model = tf.keras.Sequential([\n            efnet,\n            tf.keras.layers.Dense(256, activation='relu'),\n            tf.keras.layers.Dense(768, activation='relu'),\n            tf.keras.layers.Dense(10, activation='softmax')\n                            ])","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:11.543350Z","iopub.execute_input":"2023-04-04T04:33:11.543955Z","iopub.status.idle":"2023-04-04T04:33:12.194646Z","shell.execute_reply.started":"2023-04-04T04:33:11.543917Z","shell.execute_reply":"2023-04-04T04:33:12.193609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n                optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n                loss = 'categorical_crossentropy',\n                metrics=['categorical_accuracy']\n              )\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:12.197067Z","iopub.execute_input":"2023-04-04T04:33:12.197471Z","iopub.status.idle":"2023-04-04T04:33:12.249562Z","shell.execute_reply.started":"2023-04-04T04:33:12.197432Z","shell.execute_reply":"2023-04-04T04:33:12.248548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5)\nhistory = model.fit(train_dataset,validation_data=valid_dataset,epochs=50, callbacks = [early_stopping])","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:33:12.250615Z","iopub.execute_input":"2023-04-04T04:33:12.250983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting Model Loss Performance\nfig = plt.figure()\nplt.plot(history.history['loss'], color='green', label='loss')\nplt.plot(history.history['val_loss'], color='orange', label='val_loss')\nfig.suptitle('Loss', fontsize=20)\nplt.legend(loc='upper right')\nplt.xlabel('Epoch', fontsize=18)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting Model Accuracy Performance\nfig = plt.figure()\nplt.plot(history.history['categorical_accuracy'], color='green', label='accuracy')\nplt.plot(history.history['val_categorical_accuracy'], color='orange', label='val_accuracy')\nfig.suptitle('Accuracy', fontsize=20)\nplt.legend(loc='lower right')\nplt.xlabel('Epoch', fontsize=18)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_acc = model.evaluate(test_dataset)[1]\nprint(f'Accuracy on Test(Unseen) Dataset is \\033[1m{test_acc:.2%}\\033[0m')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = model.predict(test_dataset, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.4.1.Plot Wrongly Classified Images","metadata":{}},{"cell_type":"code","source":"predict_result = pd.DataFrame({\"path\":X_test,\n                               \"true_label\":LE.inverse_transform(y_test.argmax(axis=1)),\n                               \"predict_label\":LE.inverse_transform(predict.argmax(axis=1))})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wrong_predict = predict_result[predict_result['predict_label'] != predict_result['true_label']]\nprint(f'{len(wrong_predict)} Images are Wrongly Classified')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wrong_classified_images = []\nfor i in tqdm(wrong_predict.path.values):\n    image = cv2.imread(i)\n    wrong_classified_images.append(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Start Plotting Wrongly Classified Flowers\")\nfor i in range(len(wrong_classified_images)):\n    plt.figure(figsize=(10,10))\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(f'Predicted Category: {wrong_predict.predict_label.values[i]} - True Category: {wrong_predict.true_label.values[i]}') \n    plt.grid(False)\n    plt.imshow(cv2.cvtColor(wrong_classified_images[i], cv2.COLOR_BGR2RGB))\n    plt.show()\n    print(\" \")\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}